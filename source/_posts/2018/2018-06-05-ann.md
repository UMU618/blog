---
layout: post
title: 人工神经网络究竟是什么鬼？
date: 2018-06-05 23:12:43
categories: 宇督观
tags:
- machine-learning
- 挨踢
- 数学
---
难解释的问题，就举个简单的例子说明。PS：稣才入门，也不懂不简单的例子……

## 题目

有一个未知的函数 f(x1, x2)，其中 x1、x2 取值和结果符合下表：

| x1 | x2 | f(x1, x2) |
| -: | -: | -: |
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 0 |

求 f(x1, x2) 的表达式。

## 求解

### 人脑抢答

知道异或运算的人可以马上抢答：f(x1, x2) = x1 ^ x2，其中 ^ 是 C 语言里表示 XOR 的运算符。

很明显，这答案是准确无误的，人脑的速度还可以……

### 放开那个函数，让 AI 来！

人工神经网络（Artificial Neural Network，简称 ANN）解决问题的思路相对而言不太精确，大概就是——通过几个函数算出一个近似值，接近 0 就说是 0，接近 1 就说是 1。

首先，引入一个激活函数：

```
sigmoid(x) = 1.0 / (1 + exp(-x))
```

举个例子：sigmoid(1.777) = 1.0 / (1 + exp(-1.777)) ≈ 0.855326

类似的激活函数还有 tanh，但其实用 ReLU 更好，既简单又接近生物上的神经元。参考：[在神经网络中，激活函数sigmoid和tanh除了阈值取值外有什么不同吗？](https://www.zhihu.com/question/50396271)、[请问人工神经网络中的activation function的作用具体是什么？为什么ReLu要好过于tanh和sigmoid function?](https://www.zhihu.com/question/29021768)。但是 sigmoid 比较古老，很多教材拿它举例，稣也沿用它。

我们要求的函数是这样的：

```
f(x1, x2) = sigmoid(w1 * g(x1, x2) + w2 * h(x1, x2) + w3)
```

其中：

```
g(x1, x2) = sigmoid(wg1 * x1 + wg2 * x2 + wg3)
h(x1, x2) = sigmoid(wh1 * x1 + wh2 * x2 + wh3)
```

最终要求的是这三对系数：

```
wg1 wg2 wg3
wh1 wh2 wh3
w1 w2 w3
```

通俗说法叫求 w，其中序号为 3 的系数，又叫 bias 或者 b。

函数 f、g、h 其实就是一个神经元（neuron），结构如下：

![神经元结构图](/images/2018/20180606-ann.png)

[神经元结构图 DOT 源文件](/images/2018/20180606-ann.gv)

训练出来的一个解是：

```
-5.734 -6.029 1.777
-3.261 -3.172 4.460
-6.581 5.826 -2.444
```

下面我们来验证一下，举例 x1 = x2 = 0 比较容易算：

```
g(0, 0) = sigmoid(1.777) ≈ 0.855326
h(0, 0) = sigmoid(4.460) ≈ 0.988570
f(0.855326, 0.988569) = sigmoid(-6.581 * 0.855326 + 5.826 * 0.988570 + -2.444)
  = sigmoid(-2.313491586) ≈ 0.090012 ≈ 0
```

## 结论

ANN 就是数学的运用，训练就是在随机的 w 组合通过参考已知解逐渐纠正误差，逼出正解 w 组合。

打个比方，练习投篮的过程：肉眼观测，无数次调高低角度、出手力度、左右偏差，最终找到一套合适的参数，这个叫培养了球感……

机器学习也差不多是这样的过程，只是它比人快很多。